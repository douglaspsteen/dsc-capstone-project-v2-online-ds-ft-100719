{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting searchtweets\n",
      "  Downloading https://files.pythonhosted.org/packages/51/d7/7dd296ba9469e046bad23583aaa0d36b18c7d6e4df9fd2acfb433d1c7ee2/searchtweets-1.7.4-py3-none-any.whl\n",
      "Requirement already satisfied: requests in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from searchtweets) (2.22.0)\n",
      "Collecting tweet-parser\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/ea/cb82efb43dbcb115ea447313fbd287ff66349b34bdfdb4a78e25d3a42cb0/tweet_parser-1.13.2-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from searchtweets) (5.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (2019.11.28)\n",
      "Installing collected packages: tweet-parser, searchtweets\n",
      "Successfully installed searchtweets-1.7.4 tweet-parser-1.13.2\n"
     ]
    }
   ],
   "source": [
    "# Install searchtweets wrapper for the premium API\n",
    "\n",
    "!pip install searchtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAGCjCgEAAAAA3u1GCjoHUSbgcaYY1SP2MG9WIbo%3DwfzWYcrDUyqs0msK9VGiQCny7qBQq5jn4sWfolTSqmUj4eBVbU', 'endpoint': 'https://api.twitter.com/1.1/tweets/search/30day/flatironcapstone.json', 'extra_headers_dict': None}\n"
     ]
    }
   ],
   "source": [
    "premium_search_args = load_credentials(\"/Users/dougl/.secret/twitter_keys_30days.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)\n",
    "print(premium_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up rule to obtain tweets for last month, excluding time period  already covered by standard twitter API\n",
    "\n",
    "rule = gen_rule_payload(\"(#americanairlines OR #americanair OR @AmericanAir) -is:retweet -is:reply -RT lang:en\",\n",
    "                       results_per_call=500,\n",
    "                       from_date=\"2020-01-25 03:00\",\n",
    "                        to_date=\"2020-02-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultStream: \n",
      "\t{\n",
      "    \"username\": null,\n",
      "    \"endpoint\": \"https://api.twitter.com/1.1/tweets/search/30day/flatironcapstone.json\",\n",
      "    \"rule_payload\": {\n",
      "        \"query\": \"(#americanairlines OR #americanair OR @AmericanAir) -is:retweet -is:reply -RT lang:en\",\n",
      "        \"maxResults\": 500,\n",
      "        \"toDate\": \"202002250000\",\n",
      "        \"fromDate\": \"202001250300\"\n",
      "    },\n",
      "    \"tweetify\": true,\n",
      "    \"max_results\": 100000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rs = ResultStream(rule_payload=rule,\n",
    "                  max_results=100000,\n",
    "                  **premium_search_args)\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ResultStream.stream at 0x000001CBB5323888>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "iD = []\n",
    "datetime = []\n",
    "text = []\n",
    "retweets = []\n",
    "\n",
    "for tweet in rs.stream():\n",
    "    iD.append(tweet['id'])\n",
    "    datetime.append(tweet['created_at'])\n",
    "    try:\n",
    "        text.append(tweet['extended_tweet']['full_text'])\n",
    "    except:\n",
    "        try:\n",
    "            text.append(tweet['full_text'])\n",
    "        except:\n",
    "            text.append(tweet['text'])\n",
    "    retweets.append(tweet['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1232091470154338304</td>\n",
       "      <td>Mon Feb 24 23:54:32 +0000 2020</td>\n",
       "      <td>Joining us now Beverly Bass who was the first ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1232089893628776448</td>\n",
       "      <td>Mon Feb 24 23:48:16 +0000 2020</td>\n",
       "      <td>More @AmericanAir mechanical delays. Yo @South...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1232087057352146944</td>\n",
       "      <td>Mon Feb 24 23:37:00 +0000 2020</td>\n",
       "      <td>Check out #KidsCubsCactus for your daily dose ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1232086687125311490</td>\n",
       "      <td>Mon Feb 24 23:35:31 +0000 2020</td>\n",
       "      <td>2 days in a row. Travel nightmares.  @American...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1232086061695651840</td>\n",
       "      <td>Mon Feb 24 23:33:02 +0000 2020</td>\n",
       "      <td>Hey @AmericanAir. Making these seats smaller s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11085</td>\n",
       "      <td>1220918175329673216</td>\n",
       "      <td>Sat Jan 25 03:55:51 +0000 2020</td>\n",
       "      <td>#AmericanAirlines currently 4.5 hours delayed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11086</td>\n",
       "      <td>1220911582827491335</td>\n",
       "      <td>Sat Jan 25 03:29:39 +0000 2020</td>\n",
       "      <td>Ouch @AmericanAir flight 380 from LGA! Very ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11087</td>\n",
       "      <td>1220907874651688962</td>\n",
       "      <td>Sat Jan 25 03:14:55 +0000 2020</td>\n",
       "      <td>...48°F in #WashingtonDC. Oh boy, that's too h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11088</td>\n",
       "      <td>1220907640248832001</td>\n",
       "      <td>Sat Jan 25 03:13:59 +0000 2020</td>\n",
       "      <td>Just flew @AmericanAir and it was the hottest,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11089</td>\n",
       "      <td>1220907338699354113</td>\n",
       "      <td>Sat Jan 25 03:12:47 +0000 2020</td>\n",
       "      <td>Special thank you to @AmericanAir and @DFWAirp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11090 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                        datetime  \\\n",
       "0      1232091470154338304  Mon Feb 24 23:54:32 +0000 2020   \n",
       "1      1232089893628776448  Mon Feb 24 23:48:16 +0000 2020   \n",
       "2      1232087057352146944  Mon Feb 24 23:37:00 +0000 2020   \n",
       "3      1232086687125311490  Mon Feb 24 23:35:31 +0000 2020   \n",
       "4      1232086061695651840  Mon Feb 24 23:33:02 +0000 2020   \n",
       "...                    ...                             ...   \n",
       "11085  1220918175329673216  Sat Jan 25 03:55:51 +0000 2020   \n",
       "11086  1220911582827491335  Sat Jan 25 03:29:39 +0000 2020   \n",
       "11087  1220907874651688962  Sat Jan 25 03:14:55 +0000 2020   \n",
       "11088  1220907640248832001  Sat Jan 25 03:13:59 +0000 2020   \n",
       "11089  1220907338699354113  Sat Jan 25 03:12:47 +0000 2020   \n",
       "\n",
       "                                                    text  retweets  \n",
       "0      Joining us now Beverly Bass who was the first ...         1  \n",
       "1      More @AmericanAir mechanical delays. Yo @South...         0  \n",
       "2      Check out #KidsCubsCactus for your daily dose ...         3  \n",
       "3      2 days in a row. Travel nightmares.  @American...         0  \n",
       "4      Hey @AmericanAir. Making these seats smaller s...         0  \n",
       "...                                                  ...       ...  \n",
       "11085  #AmericanAirlines currently 4.5 hours delayed ...         1  \n",
       "11086  Ouch @AmericanAir flight 380 from LGA! Very ab...         0  \n",
       "11087  ...48°F in #WashingtonDC. Oh boy, that's too h...         0  \n",
       "11088  Just flew @AmericanAir and it was the hottest,...         0  \n",
       "11089  Special thank you to @AmericanAir and @DFWAirp...         0  \n",
       "\n",
       "[11090 rows x 4 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([])\n",
    "df = pd.concat([df, pd.Series(iD), pd.Series(datetime), pd.Series(text), pd.Series(retweets)], axis=1)\n",
    "df.columns = ['id', 'datetime', 'text', 'retweets']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert final_df to a .csv file, and save in current directory\n",
    "\n",
    "df.to_csv('twitter_30_days.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
