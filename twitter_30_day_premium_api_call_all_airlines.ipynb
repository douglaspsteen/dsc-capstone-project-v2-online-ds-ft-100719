{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ObtainMulti-Airline Tweet Data from Twitter Premium API (30-days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting searchtweets\n",
      "  Downloading https://files.pythonhosted.org/packages/51/d7/7dd296ba9469e046bad23583aaa0d36b18c7d6e4df9fd2acfb433d1c7ee2/searchtweets-1.7.4-py3-none-any.whl\n",
      "Requirement already satisfied: requests in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from searchtweets) (2.22.0)\n",
      "Collecting tweet-parser\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/ea/cb82efb43dbcb115ea447313fbd287ff66349b34bdfdb4a78e25d3a42cb0/tweet_parser-1.13.2-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from searchtweets) (5.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dougl\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->searchtweets) (2019.11.28)\n",
      "Installing collected packages: tweet-parser, searchtweets\n",
      "Successfully installed searchtweets-1.7.4 tweet-parser-1.13.2\n"
     ]
    }
   ],
   "source": [
    "# Install searchtweets wrapper for the premium API\n",
    "\n",
    "# !pip install searchtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dougl\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\searchtweets\\credentials.py:34: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  search_creds = yaml.load(f)[yaml_key]\n",
      "Grabbing bearer token from OAUTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAGCjCgEAAAAA3u1GCjoHUSbgcaYY1SP2MG9WIbo%3DwfzWYcrDUyqs0msK9VGiQCny7qBQq5jn4sWfolTSqmUj4eBVbU', 'endpoint': 'https://api.twitter.com/1.1/tweets/search/30day/flatironcapstone.json', 'extra_headers_dict': None}\n"
     ]
    }
   ],
   "source": [
    "premium_search_args = load_credentials(\"/Users/dougl/.secret/twitter_keys_30days.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)\n",
    "print(premium_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up rule to obtain tweets for last month, excluding time period  already covered by standard twitter API\n",
    "\n",
    "rule = gen_rule_payload(\"\"\"(#americanairlines OR #americanair OR @AmericanAir OR\n",
    "                            #southwestairlines OR #southwestair OR @SouthwestAir OR\n",
    "                            #unitedairlines OR #unitedair OR @united OR\n",
    "                            #deltaairlines OR #deltaair OR @delta OR \n",
    "                            #virginamerica OR #virginair OR @VirginAmerica OR \n",
    "                            #alaskaair OR #alaskaairlines OR @AlaskaAir OR\n",
    "                            #jetblue OR @JetBlue OR\n",
    "                            #spiritairlines OR #spiritair OR @SpiritAirlines OR\n",
    "                            #flyfrontier OR #frontierairlines OR @FlyFrontier OR\n",
    "                            #allegiant OR #allegiantair OR @Allegiant OR\n",
    "                            #hawaiianairlines OR @HawaiianAir OR\n",
    "                            #suncountryair OR @SunCountryAir) -is:retweet -is:reply -RT lang:en\"\"\",\n",
    "                        results_per_call=500,\n",
    "                        from_date=\"2020-02-04\",\n",
    "                        to_date=\"2020-03-04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultStream: \n",
      "\t{\n",
      "    \"username\": null,\n",
      "    \"endpoint\": \"https://api.twitter.com/1.1/tweets/search/30day/flatironcapstone.json\",\n",
      "    \"rule_payload\": {\n",
      "        \"query\": \"(#americanairlines OR #americanair OR @AmericanAir OR #southwestairlines OR #southwestair OR @SouthwestAir OR #unitedairlines OR #unitedair OR @united OR #deltaairlines OR #deltaair OR @delta OR #virginamerica OR #virginair OR @VirginAmerica OR #alaskaair OR #alaskaairlines OR @AlaskaAir OR #jetblue OR @JetBlue OR #spiritairlines OR #spiritair OR @SpiritAirlines OR #flyfrontier OR #frontierairlines OR @FlyFrontier OR #allegiant OR #allegiantair OR @Allegiant OR #hawaiianairlines OR @HawaiianAir OR #suncountryair OR @SunCountryAir) -is:retweet -is:reply -RT lang:en\",\n",
      "        \"maxResults\": 500,\n",
      "        \"toDate\": \"202003040000\",\n",
      "        \"fromDate\": \"202002040000\"\n",
      "    },\n",
      "    \"tweetify\": true,\n",
      "    \"max_results\": 150000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rs = ResultStream(rule_payload=rule,\n",
    "                  max_results=150000,\n",
    "                  **premium_search_args)\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrying request; current status code: 429\n",
      "retrying request; current status code: 429\n"
     ]
    }
   ],
   "source": [
    "iD = []\n",
    "datetime = []\n",
    "text = []\n",
    "retweets = []\n",
    "\n",
    "for tweet in rs.stream():\n",
    "    iD.append(tweet['id'])\n",
    "    datetime.append(tweet['created_at'])\n",
    "    try:\n",
    "        text.append(tweet['extended_tweet']['full_text'])\n",
    "    except:\n",
    "        try:\n",
    "            text.append(tweet['full_text'])\n",
    "        except:\n",
    "            text.append(tweet['text'])\n",
    "    retweets.append(tweet['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1234991579502243843</td>\n",
       "      <td>Tue Mar 03 23:58:32 +0000 2020</td>\n",
       "      <td>Just announced: @united says for flights booke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1234991364468690944</td>\n",
       "      <td>Tue Mar 03 23:57:40 +0000 2020</td>\n",
       "      <td>Does @Alitalia really stands on its position o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1234991343853654017</td>\n",
       "      <td>Tue Mar 03 23:57:36 +0000 2020</td>\n",
       "      <td>Hey @Delta I need to track down a past flight ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1234991315319848961</td>\n",
       "      <td>Tue Mar 03 23:57:29 +0000 2020</td>\n",
       "      <td>Hey @Delta now we’re stuck because you cancele...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1234991155688792066</td>\n",
       "      <td>Tue Mar 03 23:56:51 +0000 2020</td>\n",
       "      <td>OMG! I’m flying @americanair. All I can think ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41471</td>\n",
       "      <td>1224483897196466177</td>\n",
       "      <td>Tue Feb 04 00:04:45 +0000 2020</td>\n",
       "      <td>#United aircraft deicing at #DIA. @CBSDenver @...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41472</td>\n",
       "      <td>1224483511861571584</td>\n",
       "      <td>Tue Feb 04 00:03:13 +0000 2020</td>\n",
       "      <td>Now I know why I never check luggage. 45 mins ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41473</td>\n",
       "      <td>1224483376997945344</td>\n",
       "      <td>Tue Feb 04 00:02:41 +0000 2020</td>\n",
       "      <td>It shouldn't have taken someone suing to get #...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41474</td>\n",
       "      <td>1224483083761541122</td>\n",
       "      <td>Tue Feb 04 00:01:31 +0000 2020</td>\n",
       "      <td>After nearly 3 million miles on just @United, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41475</td>\n",
       "      <td>1224482831776342018</td>\n",
       "      <td>Tue Feb 04 00:00:31 +0000 2020</td>\n",
       "      <td>Boarding will be less stressful with the Fly D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41476 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                        datetime  \\\n",
       "0      1234991579502243843  Tue Mar 03 23:58:32 +0000 2020   \n",
       "1      1234991364468690944  Tue Mar 03 23:57:40 +0000 2020   \n",
       "2      1234991343853654017  Tue Mar 03 23:57:36 +0000 2020   \n",
       "3      1234991315319848961  Tue Mar 03 23:57:29 +0000 2020   \n",
       "4      1234991155688792066  Tue Mar 03 23:56:51 +0000 2020   \n",
       "...                    ...                             ...   \n",
       "41471  1224483897196466177  Tue Feb 04 00:04:45 +0000 2020   \n",
       "41472  1224483511861571584  Tue Feb 04 00:03:13 +0000 2020   \n",
       "41473  1224483376997945344  Tue Feb 04 00:02:41 +0000 2020   \n",
       "41474  1224483083761541122  Tue Feb 04 00:01:31 +0000 2020   \n",
       "41475  1224482831776342018  Tue Feb 04 00:00:31 +0000 2020   \n",
       "\n",
       "                                                    text  retweets  \n",
       "0      Just announced: @united says for flights booke...         1  \n",
       "1      Does @Alitalia really stands on its position o...         2  \n",
       "2      Hey @Delta I need to track down a past flight ...         0  \n",
       "3      Hey @Delta now we’re stuck because you cancele...         0  \n",
       "4      OMG! I’m flying @americanair. All I can think ...         0  \n",
       "...                                                  ...       ...  \n",
       "41471  #United aircraft deicing at #DIA. @CBSDenver @...         4  \n",
       "41472  Now I know why I never check luggage. 45 mins ...         0  \n",
       "41473  It shouldn't have taken someone suing to get #...         2  \n",
       "41474  After nearly 3 million miles on just @United, ...         0  \n",
       "41475  Boarding will be less stressful with the Fly D...         0  \n",
       "\n",
       "[41476 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([])\n",
    "df = pd.concat([df, pd.Series(iD), pd.Series(datetime), pd.Series(text), pd.Series(retweets)], axis=1)\n",
    "df.columns = ['id', 'datetime', 'text', 'retweets']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert final_df to a .csv file, and save in current directory\n",
    "\n",
    "df.to_csv('twitter_30_days_all_airlines.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
